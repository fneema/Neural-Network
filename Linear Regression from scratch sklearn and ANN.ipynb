{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression by scratch approach, sklearn library and Artificial Neural Network using Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will briefly discuss  about linear regression and later we will implement this algorithim from scratch, and using scikit learn python library. We will also build an artificial neural network using keras. The main objective of this notebook is to learn how to implement the linear regression algorithm, we are not very concerned about its performance. Before we dive into the implementation, let us first understand the algorithm. The discussion will cover the following:\n",
    "\n",
    "- What is linear regression?\n",
    "- When to use linear regression?\n",
    "- How does linear regression work?\n",
    "\n",
    "\n",
    "**1.  What is linear regression?**\n",
    "\n",
    "Linear regression is a supervised learning algorithm (It learns labelled structured data). \n",
    "\n",
    "It examines the linear relationship between a target (also known as a response or dependent variable) \n",
    "and feature(s) (also known as predictor(s) or independent variable(s)). \n",
    "\n",
    "To understand what a target and a feature is, let us look at the scenario in which we need to examine if body mass index of an adult person is associated with or related to weight and height. In this case, the body mass index is the target, while weight and height are the features. The body mass index depends on the weight and height.  \n",
    "\n",
    "There are two types of linear regression:\n",
    "\n",
    "- Univariate linear regression -  only one feature is used with a target.\n",
    "\n",
    "- Multivariate regression - two or more features are used with a target.\n",
    "\n",
    "\n",
    "**2. When to use linear regression?**\n",
    "\n",
    "Supervised learning algorthims try to solve two types of problems; regression and classification problem. \n",
    "\n",
    "Linear regression, as its name suggests and being a supervised learning algorithm, it analyses regression problems. \n",
    "\n",
    "It predicts a continous target, based on features. Features can be continous or discrete. \n",
    "\n",
    "- Therefore, inorder to use linear regression, it is important to note that the target must be continous.\n",
    "\n",
    "- Some of the advantages of this algorthim are; computationally fast and simple to interpret.\n",
    "\n",
    "- Linear regression assumes that there is a linear relationship between the target and features.\n",
    "\n",
    "- Linear regression will not perform well if the relationship between the target and the features is not linear i.e the prediction of the target will not be good.\n",
    "\n",
    "\n",
    "**How does linear regression work?**\n",
    "\n",
    "In supervised learning, the goal is to fit well a model or an **hypothesis** on a given training dataset, \n",
    "so that this model will later be used to give predictions on a new dataset also known test dataset. \n",
    "\n",
    "Linear regression model or hypothesis takes the following linear form:\n",
    "\n",
    "$$h_\\theta(x) = \\theta_0 + \\theta_1x_1 +\\theta_2x_2+...+\\theta_nx_n$$\n",
    "\n",
    "where;\n",
    "\n",
    "- $h_\\theta(x)$ is the target\n",
    "- $\\theta's$ are weights or parameters\n",
    "- $x's$ are features\n",
    "\n",
    "Now that we have a hypothesis to fit on a training dataset, we need a criterion to evaluates if our hypothesis performs well i.e it can make better predictions of the target. So what is the criterion?\n",
    "\n",
    "The criterion of a linear regression is the **cost function** (also known as the mean square error or loss function). The cost function gives the difference between the values of the actual (also known as real or observed) target and the values of predicted target.\n",
    "\n",
    "The cost function is defined as;\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{2n}\\sum_{i=1}^{n}(h_\\theta(x_i)-y_i)^2$$\n",
    "\n",
    "where;\n",
    "\n",
    "- $n$ is the number of training samples/examples\n",
    "- $h_\\theta(x_i)$ is the $i'th$ predicted value of the target\n",
    "\n",
    "- $y_i$ is the $i'th$ actual value of the target.\n",
    "\n",
    "Now, how do we use this cost function to evaluate our hypothesis? \n",
    "\n",
    "Remember we mentioned above that the cost function gives the difference between the actual values of the target and the predicted values of the target. \n",
    "\n",
    "We need to ask ourselves what will happen when the difference is big or small? The difference being big, implies that the predicted values are very far from the actual values, of which we don't need this. We need the difference to very small, that is close to zero. \n",
    "\n",
    "The measure of the difference of the cost function is determined by its parameters. \n",
    "\n",
    "We should note that parameters are unknown and we need compute them. To find the best parameters that give a small difference or minimizes the cost function, we need a learning algorithim. \n",
    "\n",
    "The most common used learning algorithm is the **Gradient Descent** which is given by\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\alpha \\Delta_\\theta J(\\theta)$$\n",
    "\n",
    "Now, we have all the necessary tools that we need for the implementation of the linear regression. Let's get down to the implementation task using these tools.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading data\n",
    "data = pd.read_csv(\"/home/aims/Documents/Kaggle Data/diabetes.csv\")\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (768, 8)\n",
      "shape of y:  (768, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Input values of features\n",
    "X = data.drop('BMI',1)\n",
    "print('shape of X: ',X.shape)\n",
    "\n",
    "#Output values of features\n",
    "y = data['BMI'].values.reshape(-1,1)\n",
    "print('shape of y: ',y.shape)\n",
    "\n",
    "#splitting data into train and test set\n",
    "x_train,x_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cost fuction\n",
    "#X-input values matrix, y-output value vector, parameter vector\n",
    "\n",
    "def cost_function(X,y,params):\n",
    "    #number of samples\n",
    "    no_samples = len(y)\n",
    "    \n",
    "    #Error- difference between predicted value of y and actual/observed value of value\n",
    "    error = (X@params) - y\n",
    "    \n",
    "    #formula for obtaining the cost\n",
    "    return (1/(2*no_samples))*np.sum(error**2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define gradient descent\n",
    "def gradient_descent(X, y, params, learning_rate, n_iters):\n",
    "    no_samples = len(y)\n",
    "    \n",
    "    #Track cost in each iteration\n",
    "    cost_track = np.zeros((n_iters,1))\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        #updating parameters\n",
    "        params = params - (learning_rate/no_samples)* X.T @ (X@params-y)\n",
    "        cost_track[i] = cost_function(X,y,params)\n",
    "    return (cost_track,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing our data/ feature scaling \n",
    "mu = np.mean(x_train,0)\n",
    "sigma = np.std(x_train,0)\n",
    "\n",
    "x_train = (x_train-mu)/sigma\n",
    "\n",
    "#Introducing bias in our input matrix\n",
    "x_train = np.hstack((np.ones((x_train.shape[0],1)),x_train))\n",
    "\n",
    "#Initialising parameters to zeros\n",
    "params = np.zeros((x_train.shape[1],1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising our test set\n",
    "x_test = (x_test-mu)/sigma\n",
    "\n",
    "#Introducing bias to test set\n",
    "x_test = np.hstack((np.ones((x_test.shape[0],1)),x_test))\n",
    "\n",
    "#predicting the y output\n",
    "y_pred = x_test@optimal_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.861001413749793"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating our model using RMSE\n",
    "rms = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Linear regression module\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calling the linear regression function from sklearn\n",
    "model = LinearRegression()\n",
    "\n",
    "#training our model\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "print('The intercept of the model is: ', model.intercept_)\n",
    "\n",
    "print('The coeffeicient of the model are: ',model.coef_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting output value of y\n",
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.861001413931367"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating our model using RMSE\n",
    "rms = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using ANN by keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X:  (768, 8)\n",
      "shape of y:  (768, 1)\n"
     ]
    }
   ],
   "source": [
    "#Input values of features\n",
    "X = data.drop('BMI',1)\n",
    "print('shape of X: ',X.shape)\n",
    "\n",
    "#Output values of features\n",
    "y = data['BMI'].values.reshape(-1,1)\n",
    "print('shape of y: ',y.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "#Performing feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "X_scaled = scaler_x.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the maximum values of the input features\n",
    "print('Maximum value of each feature',scaler_x.data_max_)\n",
    "#Checking the minimum values of the input features\n",
    "print('Minimum value of each feature', scaler_x.data_min_)\n",
    "\n",
    "#Checking the maximum values of the output\n",
    "print('Maximum value of output',scaler_y.data_max_)\n",
    "#Checking the minimum values of the output\n",
    "print('Minimum value of output', scaler_y.data_min_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking to ensure that the values of the scaled features and output are between 0 and 1.\n",
    "print(X_scaled)\n",
    "print(y_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 40)                360       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 2,041\n",
      "Trainable params: 2,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#tensflow used to build ANN\n",
    "#We can take keras as a function\n",
    "import tensorflow.keras\n",
    "\n",
    "#building model in a sequential form\n",
    "from keras.models import Sequential\n",
    "\n",
    "#for fully connceted ANN(dense)\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "#Add first layer, 45=no of neurons, 5=inputs\n",
    "model.add(Dense(40, input_dim=8, activation='relu'))\n",
    "#adding hidden layer\n",
    "model.add(Dense(40, activation='relu'))\n",
    "#adding output layer, 1=output, act=linear becoz we predict continous values\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#Generate table showing description of your ANN\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 491 samples, validate on 123 samples\n",
      "Epoch 1/10\n",
      "491/491 [==============================] - 0s 214us/step - loss: 0.1813 - val_loss: 0.0639\n",
      "Epoch 2/10\n",
      "491/491 [==============================] - 0s 15us/step - loss: 0.0355 - val_loss: 0.0220\n",
      "Epoch 3/10\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.0228 - val_loss: 0.0253\n",
      "Epoch 4/10\n",
      "491/491 [==============================] - 0s 24us/step - loss: 0.0187 - val_loss: 0.0172\n",
      "Epoch 5/10\n",
      "491/491 [==============================] - 0s 19us/step - loss: 0.0152 - val_loss: 0.0161\n",
      "Epoch 6/10\n",
      "491/491 [==============================] - 0s 26us/step - loss: 0.0143 - val_loss: 0.0145\n",
      "Epoch 7/10\n",
      "491/491 [==============================] - 0s 20us/step - loss: 0.0130 - val_loss: 0.0139\n",
      "Epoch 8/10\n",
      "491/491 [==============================] - 0s 18us/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 9/10\n",
      "491/491 [==============================] - 0s 37us/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 10/10\n",
      "491/491 [==============================] - 0s 30us/step - loss: 0.0113 - val_loss: 0.0121\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "epochs_hist = model.fit(X_train, y_train, epochs=10, batch_size=50,  verbose=1, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'loss'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fba804fb860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(epochs_hist.history.keys())\n",
    "plt.plot(epochs_hist.history['loss'])\n",
    "plt.plot(epochs_hist.history['val_loss'])\n",
    "\n",
    "plt.title('Model Loss Progression During Training/Validation')\n",
    "plt.ylabel('Training and Validation Losses')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_predict_sample = model.predict(X_test)\n",
    "\n",
    "print('Expected measure of BMI=', y_predict_sample)\n",
    "y_predict_sample_original = scaler_y.inverse_transform(y_predict_sample)\n",
    "print('Expected measure of BMI=', y_predict_sample_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10627072087221504"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating our model using RMSE\n",
    "rms = np.sqrt(mean_squared_error(y_predict_sample, y_test))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Regression from scratch using a Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self,learning_rate=0.01, num_iteration=500):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iteration = num_iteration\n",
    "    \n",
    "    def cost_fun(self, X, param,y):\n",
    "        m = len(y)\n",
    "        error = X@param\n",
    "        return (1/(2*m))*np.sum((X@param-y)**2)\n",
    "    \n",
    "    def gradient_descent(self, X, y, param):\n",
    "        #m = len(y)\n",
    "        grad = (1/len(X))* X.T @ (X@param-y)\n",
    "        #print(grad.shape)\n",
    "        return grad\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        X_copy = X.copy()\n",
    "        mu = np.mean(X_copy,0)\n",
    "        sigma = np.std(X_copy,0)\n",
    "\n",
    "        X_copy = (X_copy-mu)/sigma\n",
    "\n",
    "        X_copy = np.hstack((np.ones((X_copy.shape[0],1)),X_copy))\n",
    "        #print(X_copy.shape)\n",
    "        self.param = np.zeros((X_copy.shape[1],1))\n",
    "        for i in range(self.num_iteration):\n",
    "            #cost = self.cost_fun(X_copy,self.param,y)\n",
    "            grad = self.gradient_descent(X_copy,y, self.param).reshape(-1, 1)\n",
    "            #print(grad.shape)\n",
    "            self.param = self.param-self.learning_rate*grad\n",
    "    def predict(self,X) :\n",
    "        X_test = X.copy()\n",
    "        mu = np.mean(X_test,0)\n",
    "        sigma = np.std(X_test,0)\n",
    "\n",
    "        X_test = (X_test-mu)/sigma\n",
    "\n",
    "        #print(X_test.shape)\n",
    "        X_test = np.hstack((np.ones((X_test.shape[0],1)),X_test))\n",
    "        #print(X_test.shape)\n",
    "        return (X_test@self.param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression(learning_rate=0.01, num_iteration=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling prediction function\n",
    "pred  = lr.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.890352096087308"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluating our model using RMSE\n",
    "rms = np.sqrt(mean_squared_error(pred, y_test))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
